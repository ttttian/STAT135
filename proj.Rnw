\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[a4paper, margin=0.75in]{geometry}
\usepackage[shortlabels]{enumitem}
\usepackage{mathtools, amssymb}

\begin{document}

\title{Statistics 135 -- Lab Project}
\author{Lingtian Cheng, Yixuan Du, Ruijiao Song}
\maketitle

\section{Background}
<<Q1, echo=FALSE>>=
library("ggplot2")
library("grid")
library("gridExtra")

data.df <- na.omit(read.csv("diabetes.csv"))
@

\section{Accessing Data, Visualization and Summarization}
\begin{enumerate}[1.]
\item
\noindent
<<Q2.1, cache=TRUE, echo=FALSE, fig.align="center", fig.pos="H", fig.width=9, fig.height=3>>=
glyhb.histogram <- ggplot(data.df) +
  geom_histogram(aes(x=glyhb), binwidth=0.5)

glyhb.boxplot <- ggplot(data.df) +
  geom_boxplot(aes(x=factor(0), y=glyhb)) +
  labs(x="glyhb", y="density")

glyhb.qqplot <- ggplot(data.df) +
  stat_qq(aes(sample=glyhb)) +
  geom_abline(aes(intercept=mean(glyhb), slope=sd(glyhb)))

grid.arrange(glyhb.histogram, glyhb.boxplot, glyhb.qqplot, ncol=3,
             main="Histogram, boxplot and QQ-plot of glyhb")
@

The mean, median and mode of \texttt{glyhb} are all approximately 5. The distribution of \texttt{glyhb} is left-skewed.

\item
\noindent
<<Q2.2, cache=TRUE, echo=FALSE, fig.align="center", fig.pos="H", fig.width=9, fig.height=3>>=
chol.histogram <- ggplot(data.df) +
  geom_histogram(aes(x=chol), binwidth=15)

chol.boxplot <- ggplot(data.df) +
  geom_boxplot(aes(x=factor(0), y=chol)) +
  labs(x="chol", y="density")

chol.qqplot <- ggplot(data.df) +
  stat_qq(aes(sample=chol)) +
  geom_abline(aes(intercept=mean(chol), slope=sd(chol)))

grid.arrange(chol.histogram, chol.boxplot, chol.qqplot, ncol=3,
             main="Histogram, boxplot and QQ-plot of chol")
@

The mean, median and mode of \texttt{chol} are all approximately 200. The distribution of \texttt{chol} is better approximated with a Gaussian distribution.

\newpage

\item
\noindent
<<Q2.3, cache=TRUE, echo=FALSE, fig.align="center", fig.pos="H", fig.width=5, fig.height=2.5>>=
bp.1d.bp.1s.scatterplot <- ggplot(data.df) +
  geom_point(aes(x=bp.1d, y=bp.1s)) +
  labs(title="Scatterplot of bp.1d vs bp.1s") +
  theme(text=element_text(size=8.5))

height.age.scatterplot <- ggplot(data.df) +
  geom_point(aes(x=height, y=age)) +
  labs(title="Scatterplot of age vs height") +
  theme(text=element_text(size=8.5))

grid.arrange(bp.1d.bp.1s.scatterplot, height.age.scatterplot, ncol=2)
@

The scatterplot of \texttt{bp.1s} and \texttt{bp.1d} is near-linear, so they are approximately dependent. The scatterplot of \texttt{age} and \texttt{weight} is random, so they are approximately independent.

\item
\begin{itemize}
\item
\texttt{chol}: The two distributions have small difference, so it MAY BE a relevant feature.
\item
\texttt{stab.glu}: The two distributions have substantial difference, so it SHOULD BE a relevant feature.
\item
\texttt{hdl}: The two distributions have small difference, so it MAY BE a relevant feature.
\item
\texttt{ratio}: The two distributions have small difference, so it MAY BE a relevant feature.
\item
\texttt{age}: The two distributions have substantial difference, so it SHOULD BE a relevant feature.
\item
\texttt{height}: The two distributions have little difference, so it MAY NOT BE a relevant feature.
\item
\texttt{weight}: The two distributions have small difference, so it MAY BE a relevant feature.
\item
\texttt{bp.1s}: The two distributions have small difference, so it MAY BE a relevant feature.
\item
\texttt{bp.1d}: The two distributions have small difference, so it MAY BE a relevant feature.
\item
\texttt{waist}: The two distributions have small difference, so it MAY BE a relevant feature.
\item
\texttt{hip}: The two distributions have small difference, so it MAY BE a relevant feature.
\item
\texttt{time.ppn}: The two distributions have small difference, so it MAY NOT BE a relevant feature.
\end{itemize}

<<Q2.4, cache=TRUE, echo=FALSE, fig.align="center", fig.pos="H", fig.width=9, fig.height=12>>=
data.df <- transform(data.df,
                     glyhb.cond=ifelse(glyhb>=7, "glyhb >=7", "glyhb < 7"))

features <- c("chol", "stab.glu", "hdl", "ratio", "age", "height", "weight",
              "bp.1s", "bp.1d", "waist", "hip", "time.ppn")
feature.boxplots = list()
for (feature in features) {
  feature.boxplot <-
    ggplot(data.frame(glyhb.cond=data.df$glyhb.cond,
                      feature=data.df[[feature]])) +
    geom_boxplot(aes(x=glyhb.cond, y=feature)) +
    labs(x="glyhb", y=feature)
  feature.boxplots[[feature]] <- feature.boxplot
}

do.call(grid.arrange, c(feature.boxplots, ncol=3,
                        main="Boxplots of each feature vs glyhb"))
@

\newpage

\item
\noindent
<<Q2.5, cache=TRUE, echo=FALSE, fig.align="center", fig.pos="H", fig.width=5, fig.height=2.5>>=
data.df$BMI <- 703*data.df$weight/data.df$height^2
data.df$WHR <- data.df$waist/data.df$hip

features <- c("BMI", "WHR")
feature.boxplots = list()
for (feature in features) {
  feature.boxplot <-
    ggplot(data.frame(glyhb.cond=data.df$glyhb.cond,
                      feature=data.df[[feature]])) +
    geom_boxplot(aes(x=glyhb.cond, y=feature)) +
    labs(title=paste(c("Boxplot of", feature, "vs glyhb"), collapse=" "),
         x="glyhb", y=feature) +
    theme(text=element_text(size=8.5))
  feature.boxplots[[feature]] <- feature.boxplot
}

do.call(grid.arrange, c(feature.boxplots, ncol=2))
@

\item
In light of these first experiments, \texttt{hdl}, \texttt{stab.glu}, \texttt{age}, \texttt{weight}, \texttt{bp.1s}, \texttt{bp.1d}, \texttt{waist} and \texttt{hip} seem related to the presence of type II diabetes; \texttt{chol}, \texttt{ratio}, \texttt{height} and \texttt{time.ppn} seem unrelated to the presence of type II diabetes.

\end{enumerate}

\newpage

\section{Parametric Inference}
\begin{enumerate}[1.]
\item
$$X \sim Gamma(\alpha, \beta) = \frac{\beta^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\beta x}$$
$$E(X) = \frac{\alpha}{\beta}$$
\begin{align*}
E(X^2) & = Var(X) + [E(X)]^2 \\
& = \frac{\alpha}{\beta^2} + \left(\frac{\alpha}{\beta}\right)^2 \\
& = \frac{\alpha(\alpha+1)}{\beta^2}
\end{align*}
$$\begin{cases*}
E(X) = \frac{\alpha}{\beta} \\
E(X^2) =\frac{\alpha(\alpha+1)}{\beta^2}
\end{cases*}
\implies
\begin{cases*}
\alpha = \frac{[E(X)]^2}{Var(x)} \\
\beta = \frac{E(X)}{Var(x)}
\end{cases*}
\implies
\begin{cases*}
\hat{\alpha}_{MOM} = \frac{\overline{X}_n}{\frac{1}{n}\sum_{i=1}^n(X_i-\overline{X}_n)^2} \\
\hat{\beta}_{MOM} = \frac{\overline{X}_n^2}{\frac{1}{n}\sum_{i=1}^n(X_i-\overline{X}_n)^2}
\end{cases*}$$

<<Q3.1.1, cache=TRUE, echo=FALSE>>=
gamma.boot <- function(x) {
  alpha.mom <- mean(x)^2/var(x)
  beta.mom <- mean(x)/var(x)

  bootstrap <- sapply(1:1000, function(i) {
    samples <- sample(x, length(x), replace=TRUE)
    alpha.sample <- mean(samples)^2/var(samples)
    beta.sample <- mean(samples)/var(samples)
    return(c(alpha.sample, beta.sample))
  })

  CIs <- sapply(1:2, function(i) {
    CI <- quantile(bootstrap[i, ], probs=c(0.025, 0.975))
    return(CI)
  })
  colnames(CIs) <- c("alpha", "beta")

  return(CIs)
}

CI.BMI <- gamma.boot(data.df$BMI)
@

<<Q3.1.2>>=
################################################################################
CI.BMI
################################################################################
@

<<Q3.1.3, cache=TRUE, echo=FALSE, fig.align="center", fig.pos="H", fig.width=5, fig.height=2.5>>=
ggplot(data.df) +
  geom_histogram(aes(x=BMI, y=..density..), binwidth=2, col="white") +
  stat_function(fun=function(x)
    dgamma(x, shape=alpha.mom, rate=beta.mom), col="white") +
  labs(title="Fitted density over observed histogram of BMI") +
  theme(text=element_text(size=8.5))
@

\newpage

\item
$$\hat{\mu}_{MLE} = \overline{X}_n$$
$$\hat{\sigma}_{MLE}^2 = \frac{1}{n}\sum_{i=1}^n(X_i-\overline{X}_n)^2$$

<<Q3.2.1, cache=TRUE, echo=FALSE>>=
normal.boot <- function(x) {
  mu.mle <- mean(x)
  sigma.mle <- sd(x)

  bootstrap <- sapply(1:1000, function(i) {
    samples <- sample(x, length(x), replace=TRUE)
    mu.sample <- mean(samples)
    sigma.sample <- sd(samples)
    return(c(mu.sample, sigma.sample))
  })

  CIs <- sapply(1:2, function(i) {
    CI <- quantile(bootstrap[i, ], probs=c(0.025, 0.975))
    return(CI)
  })
  colnames(CIs) <- c("mu", "sigma")

  return(CIs)
}

CI.WHR <- normal.boot(data.df$WHR)
@

<<Q3.2.2>>=
################################################################################
CI.WHR
################################################################################
@

<<Q3.2.3, cache=TRUE, echo=FALSE, fig.align="center", fig.pos="H", fig.width=5, fig.height=2.5>>=
ggplot(data.df) +
  geom_histogram(aes(x=WHR, y=..density..), binwidth=0.025, col="white") +
  stat_function(fun=function(x)
    dnorm(x, mean=mu.mle, sd=sigma.mle), col="white") +
  labs(title="Fitted density over observed histogram of WHR") +
  theme(text=element_text(size=8.5))
@

\newpage

\item
<<Q3.3.1, cache=TRUE, echo=FALSE>>=
data.df <- transform(data.df,
  gender.glyhb.cond=ifelse(gender=="male",
    ifelse(glyhb>=7, "male & (glyhb >= 7)", "male & (glyhb < 7)"),
    ifelse(glyhb>=7, "female & (glyhb >= 7)", "female & (glyhb < 7)")))

conditions <- c("male & (glyhb >= 7)", "female & (glyhb >= 7)",
                "male & (glyhb < 7)", "female & (glyhb < 7)")

gamma.boot2 <- function(x) {
  alpha.mom <- mean(x)^2/var(x)
  beta.mom <- mean(x)/var(x)

  bootstrap <- sapply(1:1000, function(i) {
    samples <- sample(x, length(x), replace=TRUE)
    mu.sample <- mean(samples)
    sigma.sample <- sd(samples)
    return(c(mu.sample, sigma.sample))
  })

  CIs <- sapply(1:2, function(i) {
    CI <- quantile(bootstrap[i, ], probs=c(0.025, 0.975))
    return(CI)
  })
  colnames(CIs) <- c("mu", "sigma")

  return(CIs)
}

CIs.BMI <- lapply(conditions, function(x) {
  gender.glyhb.df <- subset(data.df, gender.glyhb.cond==x)
  CIs.BMI <- gamma.boot2(gender.glyhb.df$BMI)
  return(CIs.BMI)
})
names(CIs.BMI) <- conditions
@

<<Q3.3.2>>=
################################################################################
CIs.BMI
################################################################################
@

<<Q3.3.3, cache=TRUE, echo=FALSE, fig.align="center", fig.pos="H", fig.width=5, fig.height=2.5>>=
ggplot(data.df) +
  geom_boxplot(aes(x=factor(gender.glyhb.cond, levels=conditions), y=BMI)) +
  labs(title="Boxplots of BMI for each gender and glyhb condition",
       x="gender & glyhb") +
  theme(text=element_text(size=8.5))
@

\begin{itemize}
\item
On average, females have higher BMI than males.
\item
On average, people with type II diabetes (\texttt{glyhb >= 7}) have higher BMI than people without type II diabetes (\texttt{glyhb < 7}).
\item
People with type II diabetes (\texttt{glyhb >= 7}) have larger confidence intervals of both mean and standard deviation than people without type II diabetes (\texttt{glyhb < 7}), regardless of gender.
\end{itemize}

\newpage

<<Q3.3.4, cache=TRUE, echo=FALSE>>=
CIs.WHR <- lapply(conditions, function(x) {
  gender.glyhb.df <- subset(data.df, gender.glyhb.cond==x)
  CIs.WHR <- normal.boot(gender.glyhb.df$WHR)
  return(CIs.WHR)
})
names(CIs.WHR) <- conditions
@

<<Q3.3.5>>=
################################################################################
CIs.WHR
################################################################################
@

<<Q3.3.6, cache=TRUE, echo=FALSE, fig.align="center", fig.pos="H", fig.width=5, fig.height=2.5>>=
ggplot(data.df) +
  geom_boxplot(aes(x=factor(gender.glyhb.cond, levels=conditions), y=WHR)) +
  labs(title="Boxplots of WHR for each gender and glyhb condition",
       x="gender & glyhb") +
  theme(text=element_text(size=8.5))
@

\begin{itemize}
\item
On average, males have higher WHR than females.
\item
On average, people with type II diabetes (\texttt{glyhb >= 7}) have higher WHR than people without type II diabetes (\texttt{glyhb < 7}).
\item
People with type II diabetes (\texttt{glyhb >= 7}) have larger confidence intervals of both mean and standard deviation than people without type II diabetes (\texttt{glyhb < 7}), regardless of gender.
\end{itemize}

\end{enumerate}

\newpage

\section{Testing}
\begin{enumerate}[1.]
\item
<<Q4.1.1, cache=TRUE, echo=FALSE>>=
gender.glyhb.cond.table <- matrix(sapply(conditions, function(x)
  nrow(subset(data.df, gender.glyhb.cond==x))), nrow=2)
colnames(gender.glyhb.cond.table) <- c("glyhb >= 7", "glyhb < 7")
rownames(gender.glyhb.cond.table) <- c("male", "female")
@

<<Q4.1.2>>=
################################################################################
gender.glyhb.cond.table
################################################################################
fisher.test(gender.glyhb.cond.table)
################################################################################
@

Since the $p$-value is 0.655, which is greater than 0.05, we fail to reject the null hypothesis that males and females are equally exposed to type II diabetes, with 5\% significance level.

\newpage

\item
We choose to the non-parametric Kruskal-Wallis test, because it does not rely on the assumed normal distribution and less affected by outliers.

<<Q4.2.1>>=
################################################################################
kruskal.test(data.df$hdl, as.factor(data.df$glyhb.cond))
################################################################################
@

Since the $p$-value is 0.00475, which is smaller than 0.05, we reject the null hypothesis that \texttt{hdl} has equal means for those with type II diabetes and those without, with 5\% significance level.

<<Q4.2.2>>=
################################################################################
kruskal.test(data.df$bp.1s, as.factor(data.df$glyhb.cond))
################################################################################
@

Since the $p$-value is 2.034e-06, which is smaller than 0.05, we reject the null hypothesis that \texttt{bp.1s} has equal means for those with type II diabetes and those without, with 5\% significance level.

<<Q4.2.3>>=
################################################################################
kruskal.test(data.df$bp.1d, as.factor(data.df$glyhb.cond))
################################################################################
@

Since the $p$-value is 0.168, which is greater than 0.05, we fail to reject the null hypothesis that \texttt{bp.1d} has equal means for those with type II diabetes and those without, with 5\% significance level.

<<Q4.2.4>>=
################################################################################
kruskal.test(data.df$BMI, as.factor(data.df$glyhb.cond))
################################################################################
@

Since the $p$-value is 0.00198, which is smaller than 0.05, we reject the null hypothesis that \texttt{BMI} has equal means for those with type II diabetes and those without, with 5\% significance level.

<<Q4.2.5>>=
################################################################################
kruskal.test(data.df$WHR, as.factor(data.df$glyhb.cond))
################################################################################
@

Since the $p$-value is 9.95e-05, which is smaller than 0.05, we reject the null hypothesis that \texttt{WHR} has equal means for those with type II diabetes and those without, with 5\% significance level.

\item
<<Q4.3.1, cache=TRUE, echo=FALSE>>=
pi.est <- function(x, y) {
  w <- 0
  for (i in 1:length(x)) {
    for (j in 1:length(y)) {
      w <- w + (x[i] > y[j])
    }
  }
  return(w/(length(x)*length(y)))
}

male.glyhb.geq7.BMI <-
  subset(data.df, gender.glyhb.cond=="male & (glyhb >= 7)")$BMI
male.glyhb.l7.BMI <-
  subset(data.df, gender.glyhb.cond=="male & (glyhb < 7)")$BMI
male.glyhb.geq7.WHR <-
  subset(data.df, gender.glyhb.cond=="male & (glyhb >= 7)")$WHR
male.glyhb.l7.WHR <-
  subset(data.df, gender.glyhb.cond=="male & (glyhb < 7)")$WHR

pi.male.BMI <- pi.est(
  male.glyhb.geq7.BMI,
  male.glyhb.l7.BMI)
pi.male.WHR <- pi.est(
  male.glyhb.geq7.WHR,
  male.glyhb.l7.WHR)

pi.male.BMI.samples <- sapply(1:1000, function(x)
  pi.est(sample(male.glyhb.geq7.BMI, length(male.glyhb.geq7.BMI), replace=TRUE),
         sample(male.glyhb.l7.BMI, length(male.glyhb.l7.BMI), replace=TRUE)))
CI.pi.male.BMI <- quantile(pi.male.BMI.samples, probs=c(0.025, 0.975))

pi.male.WHR.samples <- sapply(1:1000, function(x)
  pi.est(sample(male.glyhb.geq7.WHR, length(male.glyhb.geq7.WHR), replace=TRUE),
         sample(male.glyhb.l7.WHR, length(male.glyhb.l7.WHR), replace=TRUE)))
CI.pi.male.WHR <- quantile(pi.male.WHR.samples, probs=c(0.025, 0.975))
@

<<Q4.3.2>>=
################################################################################
pi.male.BMI
CI.pi.male.BMI
################################################################################
pi.male.WHR
CI.pi.male.WHR
################################################################################
@

\newpage

\item
According to the result from part 3.2, we know that \texttt{WHR} has a normal distribution. We assume all patients come from the same population, so the standard deviation is constant.

$$H_0: N(\mu_0, \sigma^2)$$
$$H_1: N(\mu_1, \sigma^2)$$

<<Q4.4.1, cache=TRUE, echo=FALSE>>=
mean.male.glyhb.geq7.WHR <- mean(male.glyhb.geq7.WHR)
mean.male.glyhb.l7.WHR <- mean(male.glyhb.l7.WHR)
sd.male.WHR <- sd(subset(data.df, gender=="male")$WHR)
@

<<Q4.4.2>>=
################################################################################
mean.male.glyhb.geq7.WHR
mean.male.glyhb.l7.WHR
sd.male.WHR
################################################################################
@

$$\mu_0 = 0.906, \mu_1 = 0.949, \sigma = 0.0682$$

\begin{align*}
lik(x) & = \frac{f_0(x)}{f_1(x)} \\
& = \frac{\frac{1}{\sqrt{2\pi\sigma}}e^{-\frac{(x-\mu_0)^2}{2}}}{\frac{1}{\sqrt{2\pi\sigma}}e^{-\frac{(x-\mu_1)^2}{2}}} \\
& = e^{-2(\mu_1-\mu_0)x + (\mu_1^2-\mu_0^2)}
\end{align*}

Let $T := X$.
\begin{align*}
\alpha & = P(T > t \mid H_0) \\
& = P(\frac{T-\mu_0}{\sigma} > \frac{t-\mu_0}{\sigma}) \\
& = 1 - \Phi\left(\frac{t-\mu_0}{\sigma}\right) \\
& \implies \\
t & = \Phi^{-1}(\alpha)\sigma + \mu_0
\end{align*}
\begin{align*}
\beta & = P(T < t \mid H_1) \\
& = P(\frac{T-\mu_1}{\sigma} < \frac{t-\mu_1}{\sigma}) \\
& = \Phi\left(\frac{t-\mu_1}{\sigma}\right) \\
& = \Phi\left(\frac{\Phi^{-1}(\alpha)\sigma + \mu_0 - \mu_1}{\sigma}\right)
\end{align*}

<<Q4.4.3, cache=TRUE, echo=FALSE>>=
mu.0 <- mean.male.glyhb.l7.WHR
mu.1 <- mean.male.glyhb.geq7.WHR
sigma <- sd.male.WHR
alpha <- 0.05

t <- qnorm(1-alpha)*sigma + mu.0
beta <- pnorm((qnorm(1-alpha)*sigma + mu.0 - mu.1)/sigma)
power <- 1 - beta
@

<<Q4.4.4>>=
################################################################################
t
power
################################################################################
@

$$\alpha \leqslant 5\% \implies 1-\beta \leqslant 0.156$$

We construct a test for type II diabetes for male patient that we reject the null hypothesis if his \texttt{WHR} $\geqslant$ 1.018. The significance of the test is $\leqslant$ 5\% and the power of the test is $\leqslant$ 0.156.

\newpage

\item
<<Q4.5.1, cache=TRUE, echo=FALSE>>=
BMI.labels <- c("Underweight", "Healthy", "Overweight",
                       "Level 1 Obese", "Level 2 Obese", "Level 3 Obese")
data.df$BMI.std <- cut(data.df$BMI, breaks=c(0, 18.5, 25, 30, 35, 40, Inf),
                       labels=BMI.labels, right=F)

gender.BMI.categories <- cbind(table(subset(data.df, gender=="male")$BMI.std),
                               table(subset(data.df, gender=="female")$BMI.std))
colnames(gender.BMI.categories) <- c("male", "female")
@

<<Q4.5.2, warning=FALSE>>=
################################################################################
gender.BMI.categories
################################################################################
chisq.test(gender.BMI.categories)
################################################################################
@

Since the $p$-value is 0.000119, which is smaller than 0.05, we reject the null hypothesis that male and female population sample has homogeneous distribution of BMI categories, with 5\% significance level.

<<Q4.5.3, cache=TRUE, echo=FALSE>>=
WHR.labels <- c("Low", "Moderate", "High", "Very High")
data.df$WHR.std <- factor(NA)
levels(data.df$WHR.std) <- WHR.labels

gender.age.cond <-
  data.df$gender=="male" & data.df$age >= 20 & data.df$age <= 29
data.df[gender.age.cond, ]$WHR.std <-
  cut(data.df[gender.age.cond, ]$WHR,
      breaks=c(0, 0.83, 0.88, 0.94, Inf), labels=WHR.labels)

gender.age.cond <-
  data.df$gender=="male" & data.df$age >= 30 & data.df$age <= 39
data.df[gender.age.cond, ]$WHR.std <-
  cut(data.df[gender.age.cond, ]$WHR,
      breaks=c(0, 0.84, 0.91, 0.96, Inf), labels=WHR.labels)

gender.age.cond <-
  data.df$gender=="male" & data.df$age >= 40 & data.df$age <= 49
data.df[gender.age.cond, ]$WHR.std <-
  cut(data.df[gender.age.cond, ]$WHR,
      breaks=c(0, 0.88, 0.95, 1, Inf), labels=WHR.labels)

gender.age.cond <-
  data.df$gender=="male" & data.df$age >= 50 & data.df$age <= 59
data.df[gender.age.cond, ]$WHR.std <-
  cut(data.df[gender.age.cond, ]$WHR,
      breaks=c(0, 0.90, 0.96, 1.02, Inf), labels=WHR.labels)

gender.age.cond <-
  data.df$gender=="male" & data.df$age >= 60
data.df[gender.age.cond, ]$WHR.std <-
  cut(data.df[gender.age.cond, ]$WHR,
      breaks=c(0, 0.91, 0.98, 1.03, Inf), labels=WHR.labels)

gender.age.cond <-
  data.df$gender=="female" & data.df$age >= 20 & data.df$age <= 29
data.df[gender.age.cond, ]$WHR.std <-
  cut(data.df[gender.age.cond, ]$WHR,
      breaks=c(0, 0.71, 0.77, 0.82, Inf), labels=WHR.labels)

gender.age.cond <-
  data.df$gender=="female" & data.df$age >= 30 & data.df$age <= 39
data.df[gender.age.cond, ]$WHR.std <-
  cut(data.df[gender.age.cond, ]$WHR,
      breaks=c(0, 0.72, 0.78, 0.84, Inf), labels=WHR.labels)

gender.age.cond <-
  data.df$gender=="female" & data.df$age >= 40 & data.df$age <= 49
data.df[gender.age.cond, ]$WHR.std <-
  cut(data.df[gender.age.cond, ]$WHR,
      breaks=c(0, 0.73, 0.79, 0.87, Inf), labels=WHR.labels)

gender.age.cond <-
  data.df$gender=="female" & data.df$age >= 50 & data.df$age <= 59
data.df[gender.age.cond, ]$WHR.std <-
  cut(data.df[gender.age.cond, ]$WHR,
      breaks=c(0, 0.74, 0.81, 0.88, Inf), labels=WHR.labels)

gender.age.cond <-
  data.df$gender=="female" & data.df$age >= 60
data.df[gender.age.cond, ]$WHR.std <-
  cut(data.df[gender.age.cond, ]$WHR,
      breaks=c(0, 0.76, 0.83, 0.9, Inf), labels=WHR.labels)

gender.WHR.categories <- cbind(table(subset(data.df, gender=="male")$WHR.std),
                               table(subset(data.df, gender=="female")$WHR.std))
colnames(gender.WHR.categories) <- c("male", "female")
@

<<Q4.5.4>>=
################################################################################
gender.WHR.categories
################################################################################
chisq.test(gender.WHR.categories)
################################################################################
@

Since the $p$-value is 2.2e-16, which is smaller than 0.05, we reject the null hypothesis that male and female population sample has homogeneous distribution of WHR categories, with 5\% significance level.

\item
<<Q4.6.1>>=
################################################################################
summary(aov(glyhb ~ BMI.std * WHR.std, data.df))
################################################################################
@

The interaction effect between \texttt{BMI} and \texttt{WHR} is not significant. \texttt{BMI} is more sensitive to \texttt{glyhb}. Overall, the result is consistent with part 3.3.

\end{enumerate}

\newpage

\section{Regression}
\begin{enumerate}[1.]
\item
According to the result from part 2.2, we consider \texttt{stab.glu}, \texttt{age}, \texttt{BMI} and \texttt{WHR} the most relevant features for predicting type II diabetes.

<<Q5.1.1, cache=TRUE, echo=FALSE>>=
glyhb.lm <-
  lm(glyhb ~ scale(stab.glu) + scale(age) + scale(BMI) + scale(WHR), data.df)
glyhb.fit <- predict(glyhb.lm, data.df)

threshold <- function(y, lambda) {
  return(ifelse(y > lambda, 1, 0))
}

err.rate <- function(lambda) {
  rate <- mean(sapply(data.df$glyhb, function(x) threshold(x, lambda)) !=
                 sapply(glyhb.fit, function(x) threshold(x, lambda)))
  return(rate)
}
@

<<Q5.1.2>>=
################################################################################
err.rate(lambda=7)
################################################################################
@

\item
<<Q5.2.1, cache=TRUE, echo=FALSE>>=
false.pos.rate <- function(lambda) {
  rate <- mean(sapply(data.df$glyhb, function(x) threshold(x, lambda)) <
                 sapply(glyhb.fit, function(x) threshold(x, lambda)))
  return(rate)
}

false.neg.rate <- function(lambda) {
  rate <- mean(sapply(data.df$glyhb, function(x) threshold(x, lambda)) >
                 sapply(glyhb.fit, function(x) threshold(x, lambda)))
  return(rate)
}
@

<<Q5.2.2>>=
################################################################################
false.pos.rate(lambda=7)
false.neg.rate(lambda=7)
################################################################################
@

The False Negatives Rate is 5.29\%, which already meets the specifications. The False Positives Rate is 1.95\%.

\item
<<Q5.3.1>>=
################################################################################
coefficients(glyhb.lm)
################################################################################
@

\texttt{stab.glu} has the largest influence.

<<Q5.3.2>>=
################################################################################
summary(lm(glyhb ~ hdl + bp.1s + bp.1d, data.df))
################################################################################
@

Since the $p$-value is 9.485e-07, we reject the null hypothesis that \texttt{hdl}, \texttt{bp.1s} and \texttt{bp.1d} do not have any predictive value, with 5\% significance level.

\item
According to the result from 4.6, \texttt{BMI} and \texttt{WHR} do not interact. However, if they do interact, we would choose the feature with larger influence (\texttt{BMI} in this case), because the interaction effect will reduce the influence.

\item

\item

\item
\end{enumerate}

\newpage

\appendix
\section{Appendix}
\subsection{Background}
<<eval=FALSE>>=
<<Q1>>
@

\subsection{Accessing Data, Visualization and Summarization}
\begin{enumerate}[1.]
\item
<<eval=FALSE>>=
<<Q2.1>>
@

\item
<<eval=FALSE>>=
<<Q2.2>>
@

\item
<<eval=FALSE>>=
<<Q2.3>>
@

\item
<<eval=FALSE>>=
<<Q2.4>>
@

\item
<<eval=FALSE>>=
<<Q2.5>>
@
\end{enumerate}

\subsection{Parametric Inference}
\begin{enumerate}[1.]
\item
<<eval=FALSE>>=
<<Q3.1.1>>

<<Q3.1.3>>
@

\item
<<eval=FALSE>>=
<<Q3.2.1>>

<<Q3.2.3>>
@

\item
<<eval=FALSE>>=
<<Q3.3.1>>

<<Q3.3.3>>

<<Q3.3.4>>

<<Q3.3.6>>
@
\end{enumerate}

\subsection{Testing}
\begin{enumerate}[1.]
\item
<<eval=FALSE>>=
<<Q4.1.1>>
@

\addtocounter{enumi}{1}

\item
<<eval=FALSE>>=
<<Q4.3.1>>
@

\item
<<eval=FALSE>>=
<<Q4.4.1>>

<<Q4.4.3>>
@

\item
<<eval=FALSE>>=
<<Q4.5.1>>

<<Q4.5.3>>
@
\end{enumerate}

\subsection{Regression}
\begin{enumerate}[1.]
\item
<<eval=FALSE>>=
<<Q5.1.1>>
@

\item
<<eval=FALSE>>=
<<Q5.2.1>>
@
\end{enumerate}
\end{document}
